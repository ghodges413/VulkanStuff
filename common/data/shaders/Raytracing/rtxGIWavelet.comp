#version 450
// This denoiser is based on the paper: https://research.nvidia.com/publication/2017-07_spatiotemporal-variance-guided-filtering-real-time-reconstruction-path-traced
// Spatiotemporal Variance-Guided Filtering: Real-Time Reconstruction for Path-Traced Global Illumination

#define WORK_GROUP_SIZE 8
layout ( local_size_x = WORK_GROUP_SIZE, local_size_y = WORK_GROUP_SIZE, local_size_z = 1 ) in;

layout( push_constant ) uniform pushIters {
    ivec4 iteration;
} PushConstant;

layout( binding = 0 ) uniform uboCamera {
    mat4 view;
    mat4 proj;
} camera;

layout( binding = 1 ) uniform writeonly image2D imageDestRed;	// The buffer that will be filtered
layout( binding = 2 ) uniform writeonly image2D imageDestGreen;	// The buffer that will be filtered
layout( binding = 3 ) uniform writeonly image2D imageDestBlue;	// The buffer that will be filtered

layout( binding = 4, rgba16f ) uniform readonly image2D imageSourceRed;	// The accumulated color buffer
layout( binding = 5, rgba16f ) uniform readonly image2D imageSourceGreen;	// The accumulated color buffer
layout( binding = 6, rgba16f ) uniform readonly image2D imageSourceBlue;	// The accumulated color buffer

layout( binding = 7, rgba32f ) uniform readonly image2D imageGBuffer0;
layout( binding = 8, rgba16f ) uniform readonly image2D imageGBuffer1;
layout( binding = 9, rgba16f ) uniform readonly image2D imageGBuffer2;

layout( binding = 10, rgba16f ) uniform readonly image2D imageLumaSrc;
layout( binding = 11, rgba16f ) uniform writeonly image2D imageLumaDst;

//const float kernels[5] = { 1.0/16.0, 1.0/4.0, 3.0/8.0, 1.0/4.0, 1.0/16.0 };
const float kernels[5] = { 1.0/6.0, 2.0/3.0, 1.0, 2.0/3.0, 1.0/6.0 };

// These are hard coded values that the authors of the SVGF paper found worked
const float sigmaZ = 1;
const float sigmaN = 128;
const float sigmaL = 4;

const float epsilonZ = 0.001;
const float epsilonL = 0.001;

float gradP = 0;

/*
==========================
FilterWeightPos
==========================
*/
float FilterWeightPos( in float pDepth, in vec3 qPos ) {
	vec4 qPosProj = camera.proj * camera.view * vec4( qPos.xyz, 1.0 );
	float qDepth = qPosProj.z / qPosProj.w;

	float gradZp = gradP;
	float numerator = abs( pDepth - qDepth );
	float denominator = sigmaZ * abs( gradZp * ( pDepth - qDepth ) ) + epsilonZ;
	return exp( -numerator / denominator );
}

/*
==========================
FilterWeightNorm
==========================
*/
float FilterWeightNorm( in vec3 pNorm, in vec3 qNorm ) {
	return pow( max( 0.0, dot( pNorm, qNorm ) ), sigmaN );
}

/*
==========================
FilterWeightLuminance
==========================
*/
float FilterWeightLuminance( in vec3 pColor, in vec3 qColor, in vec4 luma ) {
	float pLum = dot( vec3( 0.2126, 0.7152, 0.0722 ), pColor.rgb );
	float qLum = dot( vec3( 0.2126, 0.7152, 0.0722 ), qColor.rgb );

	//float varianceSqr = pColor.a;	// Stored from the accumulator shader
	float varianceSqr = abs( luma.z );
	float numerator = abs( pLum - qLum );
	float denominator = sigmaL * sqrt( varianceSqr ) + epsilonL;
	//return exp( -numerator / denominator );
	return 1;
}

/*
==========================
FilterWeightLuminance2
==========================
*/
float FilterWeightLuminance2( in vec3 pColor, in vec3 qColor, in float varSqr ) {
	float pLum = dot( vec3( 0.2126, 0.7152, 0.0722 ), pColor.rgb );
	float qLum = dot( vec3( 0.2126, 0.7152, 0.0722 ), qColor.rgb );

	//const float sigmaColor = 10.0;
	//const float epsilonVar = 1e-10;
	//float denominator = sigmaColor * sqrt( max( 0.0, epsilonVar + varSqr ) );
	//float denominator = sigmaColor * sqrt( max( 0.0, varSqr ) ) + epsilonVar;
	float denominator = sigmaL * sqrt( max( 0.0, varSqr ) ) + epsilonL;
	//float denominator = sigmaL * sqrt( abs( varSqr ) ) + epsilonL;

	const float weight = abs( pLum - qLum ) / denominator;
	return exp( -weight );
	//return 1;
}

vec3 ColorFromSH( in vec4 shRed, in vec4 shGreen, in vec4 shBlue, in vec3 dir ) {
	const float c1 = 0.429043;
    const float c2 = 0.511664;
    const float c3 = 0.743125;
    const float c4 = 0.886227;
    const float c5 = 0.247708;

	// Convert to spherical harmonic components
    vec3 ylm00 = vec3( shRed.x, shGreen.x, shBlue.x );
    vec3 ylm11 = vec3( shRed.y, shGreen.y, shBlue.y );
    vec3 ylm10 = vec3( shRed.z, shGreen.z, shBlue.z );
    vec3 ylm1n1 = vec3( shRed.w, shGreen.w, shBlue.w );

    vec3 color = ylm00 * c4 + ( ylm11 * dir.x + ylm1n1 * dir.y + ylm10 * dir.z ) * 2.0 * c2;
    return color;
}

/*
==========================
SpatialVarianceSqr
3x3 gaussian blur of the variance
==========================
*/
float SpatialVarianceSqr( ivec2 st ) {
    const float kernel[2][2] = {
        { 1.0 / 4.0, 1.0 / 8.0 },
        { 1.0 / 8.0, 1.0 / 16.0 },
    };

	float sum = 0.0;
	float sumSqr = 0.0;
	float num = 0;
	for ( int j = 0; j < 3; j++ ) {
		for ( int i = 0; i < 3; i++ ) {
			int x = ( i - 1 ); // -1, 0, 1
			int y = ( j - 1 ); // -1, 0, 1
			float k = kernel[ abs( x ) ][ abs( y ) ];

			vec4 pColorR = imageLoad( imageSourceRed, st + ivec2( x, y ) );
			vec4 pColorG = imageLoad( imageSourceGreen, st + ivec2( x, y ) );
			vec4 pColorB = imageLoad( imageSourceBlue, st + ivec2( x, y ) );

			vec4 gbuffer2 = imageLoad( imageGBuffer2, st + ivec2( x, y ) );
			vec3 normal = gbuffer2.xyz;

			vec3 pColor = ColorFromSH( pColorR, pColorG, pColorB, normal );

			float pLum = dot( vec3( 0.2126, 0.7152, 0.0722 ), pColor.rgb );
			sum += pLum * k;
			sumSqr += pLum * k * pLum * k;
			num += 1.0;
		}

	}

	//sum /= num;
	//sumSqr /= num;
	//float varSqr = sum * sum - sumSqr;
	//return varSqr;
    return sum;
}

/*
==========================
main
==========================
*/
void main() {
	ivec2 st = ivec2( gl_GlobalInvocationID.xy );
	if ( st.x >= 1920 || st.y >= 1080 ) {
		return;
	}

	vec4 gbuffer0 = imageLoad( imageGBuffer0, st );
    vec4 gbuffer1 = imageLoad( imageGBuffer1, st );
    vec4 gbuffer2 = imageLoad( imageGBuffer2, st );

	vec3 worldPos = gbuffer0.xyz;
    vec3 diffuse = gbuffer1.rgb;
    vec3 normal = gbuffer2.xyz;

	float roughness = gbuffer0.a;
    float metalness = gbuffer1.a;

    if ( 0 == gbuffer2.a ) {
		imageStore( imageDestRed, st, vec4( 0 ) );
		imageStore( imageDestGreen, st, vec4( 0 ) );
		imageStore( imageDestBlue, st, vec4( 0 ) );
		return;
    }

	//
	//	Calculate the gradient of the depth
	//
	float pDepth = 0;
	{
		vec4 posPX = imageLoad( imageGBuffer0, st + ivec2( 1, 0 ) );
		vec4 posPY = imageLoad( imageGBuffer0, st + ivec2( 0, 1 ) );
		vec4 posNX = imageLoad( imageGBuffer0, st + ivec2(-1, 0 ) );
		vec4 posNY = imageLoad( imageGBuffer0, st + ivec2( 0,-1 ) );

		posPX = camera.proj * camera.view * vec4( posPX.xyz, 1.0 );
		posPY = camera.proj * camera.view * vec4( posPY.xyz, 1.0 );
		posNX = camera.proj * camera.view * vec4( posNX.xyz, 1.0 );
		posNY = camera.proj * camera.view * vec4( posNY.xyz, 1.0 );

		posPX /= posPX.w;
		posPY /= posPY.w;
		posNX /= posNX.w;
		posNY /= posNY.w;

		vec4 projPos = camera.proj * camera.view * vec4( worldPos.xyz, 1.0 );
		projPos /= projPos.w;
		pDepth = projPos.z;

		float dDepthX = ( posPX.z - posNX.z ) * 0.5 / projPos.z;	// We divied by projPos.z to "normalize" the depth
		float dDepthY = ( posPY.z - posNY.z ) * 0.5 / projPos.z;

		// TODO: Both of these are tried in real world code, but experiment and see what works for us
		gradP = sqrt( dDepthX * dDepthX + dDepthY * dDepthY );
		gradP = max( abs( dDepthX ), abs( dDepthY ) );
	}

	vec3 pPos = worldPos;
	vec3 pNorm = normal;
	vec4 pColorR = imageLoad( imageSourceRed, st );
	vec4 pColorG = imageLoad( imageSourceGreen, st );
	vec4 pColorB = imageLoad( imageSourceBlue, st );
	vec3 pColor = ColorFromSH( pColorR, pColorG, pColorB, normal );
	vec4 pLuma = imageLoad( imageLumaSrc, st );
    float varSqr = SpatialVarianceSqr( st );

	// Sample the 5x5 pixel block and convolve with filter weights
	int iter = PushConstant.iteration.x;
	int dx = ( 1 << iter );

	float wSum = 0;
	vec2 momentSum = vec2( 0 );
	float denominator = 0;
	vec4 numeratorR = vec4( 0 );
	vec4 numeratorG = vec4( 0 );
	vec4 numeratorB = vec4( 0 );
	for ( int j = 0; j < 5; j++ ) {
		for ( int i = 0; i < 5; i++ ) {
			float kernel = kernels[ i ] * kernels[ j ];

			int x = ( i - 2 );// 0 = -2, 1 = -1, 2 = 0, 3 = 1, 3 = 2
			int y = ( j - 2 );// 0 = -2, 1 = -1, 2 = 0, 3 = 1, 3 = 2
			ivec2 offset = ivec2( x, y ) * dx;

			vec3 qPos = imageLoad( imageGBuffer0, st + offset ).xyz;
			vec3 qNorm = imageLoad( imageGBuffer2, st + offset ).xyz;
			vec4 qColorR = imageLoad( imageSourceRed, st + offset );
			vec4 qColorG = imageLoad( imageSourceGreen, st + offset );
			vec4 qColorB = imageLoad( imageSourceBlue, st + offset );
			vec3 qColor = ColorFromSH( qColorR, qColorG, qColorB, qNorm );

			float wZ = FilterWeightPos( pDepth, qPos );
			float wN = FilterWeightNorm( pNorm, qNorm );
			//float wL = FilterWeightLuminance( pColor, qColor, pLuma );
			float wL = FilterWeightLuminance2( pColor, qColor, varSqr );
			float wpq = wZ * wN * wL;

			numeratorR += kernel * wpq * qColorR;
			numeratorG += kernel * wpq * qColorG;
			numeratorB += kernel * wpq * qColorB;
			denominator += kernel * wpq;

			vec4 qLuma = imageLoad( imageLumaSrc, st );
			momentSum += qLuma.xy * wpq;

			wSum += wpq;
		}
	}

	// Average the luma's and calculate the variance
	momentSum /= wSum;
	float lumaVariance = momentSum.g - momentSum.r * momentSum.r;
	imageStore( imageLumaDst, st, vec4( momentSum.x, momentSum.y, lumaVariance, lumaVariance ) );

	vec4 colorR = numeratorR / denominator;
	vec4 colorG = numeratorG / denominator;
	vec4 colorB = numeratorB / denominator;
	imageStore( imageDestRed, st, colorR );
	imageStore( imageDestGreen, st, colorG );
	imageStore( imageDestBlue, st, colorB );
}